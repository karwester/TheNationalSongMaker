{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get songs from one of the lyrics websites and save them in a text file\n",
    "I now have a dictionary with albums and song titles saved as a pickle. I need to go to one of the lyrics pages, find song lyrics for each album and save them in a text file. Fist I need to load my pickle file and check my song titles are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "pathCore = \"C:\\\\Users\\\\karol\\\\jupyter_startUp_dir\\\\TheNationalSongMaker\"\n",
    "os.chdir(pathCore)\n",
    "with open('theNationalSongDictionary.pickle', 'rb') as handle:\n",
    "    theNationalSongDictionary = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Virginia EP': ['\"You\\'ve Done It Again, Virginia\"', '\"Santa Clara\"', '\"Blank Slate\"', '\"Tall Saint\"', '\"Without Permission\"', '\"Forever After Days\"', '\"Rest of Years\"', '\"Slow Show\"', '\"Lucky You\"', '\"Mansion on the Hill\"', '\"Fake Empire\"', '\"About Today\"'], 'Cherry Tree': ['\"Wasp Nest\"', '\"All the Wine\"', '\"All Dolled-Up in Straps\"', '\"Cherry Tree\"', '\"About Today\"', '\"Murder Me Rachael\"', '\"A Reasonable Man (I Don\\'t Mind)\"'], 'Sad Songs for Dirty Lovers': ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], 'Alligator': ['\"Secret Meeting\"', '\"Karen\"', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\"', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\"', '\"All the Wine\"', '\"Abel\"', '\"The Geese of Beverly Road\"', '\"City Middle\"', '\"Mr. November\"'], 'Boxer': ['\"Fake Empire\"', '\"Mistaken for Strangers\"', '\"Brainy\"', '\"Squalor Victoria\"', '\"Green Gloves\"', '\"Slow Show[25]\"', '\"Apartment Story\"', '\"Start a War\"', '\"Guest Room\"', '\"Racing Like a Pro\"', '\"Ada\"', '\"Gospel\"'], 'High Violet': ['\"Terrible Love\"', '\"Sorrow\"', '\"Anyone\\'s Ghost\"', '\"Little Faith\"', '\"Afraid of Everyone\"', '\"Bloodbuzz Ohio\"', '\"Lemonworld\"', '\"Runaway\"', '\"Conversation 16\"', '\"England\"', '\"Vanderlyle Crybaby Geeks\"'], 'The National': ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], 'Trouble Will Find Me': ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\"', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\"', '\"This Is the Last Time\"', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\"', '\"Pink Rabbits\"', '\"Hard to Find\"'], 'Sleep Well Beast': ['\"Nobody Else Will Be There\"', '\"Day I Die\"', '\"Walk It Back\"', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']}\n"
     ]
    }
   ],
   "source": [
    "print(theNationalSongDictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK,we have a dictionary with all the songs now. Let's get all the lyrincs from www.lyrics.com.\n",
    "Use beutiful soup, ?selenium?\n",
    "First go to The National page:\n",
    "https://www.lyrics.com/artist/The-National/13762\n",
    "\n",
    "Find songs matching dictionary values, click and go to page, scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you tell re-enchantment I said goodbye\n",
      "I met a girl named disillusionment\n",
      "Could you tell her I made the headlines\n",
      "This is a boy who draws wings on everything\n",
      "\n",
      "Could you tell her to check the headlines\n",
      "This is a boy who finds angels in the river\n",
      "You know I dreamed about you\n",
      "For twenty-nine years before\n",
      "I saw you\n",
      "\n",
      "You know I dreamed about you\n",
      "I missed you for twenty-nine years\n",
      "Birds flyin' out of order\n",
      "Underneath the sky\n",
      "\n",
      "I'll run up to the rainbow girl\n",
      "Just to pass her by\n",
      "And I'll never have a change of heart\n",
      "I've sworn I'd never sing\n",
      "\n",
      "I have no heart this one is gone\n",
      "And now I wear the wings\n",
      "You know I dreamed about you\n",
      "For twenty-nine years before\n",
      "I saw you\n",
      "\n",
      "You know I dreamed about you (twenty-nine years)\n",
      "I missed you for twenty-nine years\n",
      "You know I dreamed about you\n",
      "For twenty-nine years before I saw you\n",
      "\n",
      "You know I dreamed about you\n",
      "For twenty-nine years \n",
      "Before I saw you\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.lyrics.com/artist/The-National/13762\" \n",
    "\n",
    "#####\n",
    "\n",
    "driver = webdriver.Chrome(\"C:/Users/karol/drivers/chromedriver\")  #select selenium web driver\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(url) #open the url in selenium\n",
    "\n",
    "#link = driver.find_element_by_link_text('Details')\n",
    "\n",
    "link = driver.find_element_by_link_text(\"29 Years\").click()\n",
    "\n",
    "\n",
    "#print(link)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html5lib') #grab the content with beautifulsoup for parsing\n",
    "    #main_table = soup.findAll(\"pre\",{\"class\":\"item\"}) \n",
    "div = soup.find(id=\"lyric-body-text\").text\n",
    "print(div)\n",
    "    \n",
    "    #id =lyric-body-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # After some experimentation with the https://www.lyrics.com I discovered some of the songs are missing. I found a site with a more complete list at: https://www.azlyrics.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Songs for each album will be saved in separate folders named after album name. We will need to create titles for folders with songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheVirginiaEp\n",
      "CherryTree\n",
      "SadSongsForDirtyLovers\n",
      "Alligator\n",
      "Boxer\n",
      "HighViolet\n",
      "TheNational\n",
      "TroubleWillFindMe\n",
      "SleepWellBeast\n"
     ]
    }
   ],
   "source": [
    "#for each album in a list ceate a string,\n",
    "#capitalise all words and remove spaces\n",
    "albumNum = 0\n",
    "for albumNum in range(0, len(theNationalSongDictionary)):\n",
    "    print(list(theNationalSongDictionary.keys())[albumNum].title().replace(\" \", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\TheVirginiaEp\n",
      "exists\n",
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\CherryTree\n",
      "exists\n",
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\SadSongsForDirtyLovers\n",
      "exists\n",
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\Alligator\n",
      "exists\n",
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\Boxer\n",
      "Fake Empire\n",
      "https://www.azlyrics.com/lyrics/national/fakeempire.html\n",
      "2\n",
      "Mistaken For Strangers\n",
      "https://www.azlyrics.com/lyrics/national/mistakenforstrangers.html\n",
      "2\n",
      "Brainy\n",
      "https://www.azlyrics.com/lyrics/national/brainy.html\n",
      "2\n",
      "Squalor Victoria\n",
      "https://www.azlyrics.com/lyrics/national/squalorvictoria.html\n",
      "2\n",
      "Green Gloves\n",
      "https://www.azlyrics.com/lyrics/national/greengloves.html\n",
      "2\n",
      "Slow Show\n",
      "https://www.azlyrics.com/lyrics/national/slowshow.html\n",
      "2\n",
      "Apartment Story\n",
      "https://www.azlyrics.com/lyrics/national/apartmentstory.html\n",
      "2\n",
      "Start A War\n",
      "https://www.azlyrics.com/lyrics/national/startawar.html\n",
      "2\n",
      "Guest Room\n",
      "https://www.azlyrics.com/lyrics/national/guestroom.html\n",
      "2\n",
      "Racing Like A Pro\n",
      "https://www.azlyrics.com/lyrics/national/racinglikeapro.html\n",
      "2\n",
      "Ada\n",
      "https://www.azlyrics.com/lyrics/national/ada.html\n",
      "2\n",
      "Gospel\n",
      "https://www.azlyrics.com/lyrics/national/gospel.html\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "\n",
    "def title_one_liner(title):\n",
    "    return re.sub(r\"(?<=[a-z])[\\']([A-Z])\", lambda x: x.group().lower(), title.title())\n",
    "url = \"https://www.azlyrics.com/n/national.html\" \n",
    "\n",
    "#####\n",
    "\n",
    "driver = webdriver.Chrome(\"C:/Users/karol/drivers/chromedriver\")  #select selenium web driver\n",
    "driver.implicitly_wait(20)\n",
    "driver.get(url) #open the url in selenium\n",
    "\n",
    "pathCore = \"C:\\\\Users\\\\karol\\\\jupyter_startUp_dir\\\\TheNationalSongMaker\"\n",
    "\n",
    "albumNum = 0\n",
    "for albumNum in range(0, len(theNationalSongDictionary)):\n",
    "    albumTitle = list(theNationalSongDictionary.keys())[albumNum].title().replace(\" \", \"\")\n",
    "    albumSongs =list(theNationalSongDictionary.values())[albumNum]\n",
    "    #print(list(theNationalSongDictionary.keys())[albumNum].title().replace(\" \", \"\"))\n",
    "#pathToAlbumFolder = pathCore + \"\\\\\" + \"theVirginiaEP\"\n",
    "    pathToAlbumFolder = pathCore + \"\\\\\" + albumTitle\n",
    "    print(pathToAlbumFolder)\n",
    "    \n",
    "    if os.path.exists(pathToAlbumFolder): #if the folder exists\n",
    "        print(\"exists\")\n",
    "    elif not os.path.exists(pathToAlbumFolder):\n",
    "        os.makedirs(pathToAlbumFolder)\n",
    "        os.chdir(pathToAlbumFolder)\n",
    "\n",
    "\n",
    "\n",
    "#for song in album:\n",
    "        for song in albumSongs:\n",
    "            #print(song)\n",
    "            song_no_quotes = (song.strip('\\\"'))  #need to remove quotes\n",
    "            song_no_quotes=song_no_quotes.split('(')[0] #remove anything in brackets, eg in A Reasonable Man (I Don'T Mind)\n",
    "\n",
    "            #PROBLEM we want to not capitalise after hyphenation, but do want to capitalise after a dash\n",
    "            #solutin here: https://daviseford.com/blog/2017/04/27/python-string-to-title-including-punctuation.html\n",
    "\n",
    "            #song_no_quotes =string.capwords(song_no_quotes)#need to capitalise everything, articles in my list are not capitalised, and in the page are\n",
    "            #song_no_quotes =song_no_quotes.title()#unlike capwords, will capitalise after hyphenation, we don't want that\n",
    "\n",
    "            song_no_quotes=title_one_liner(song_no_quotes)\n",
    "\n",
    "            #special rule for Reasonable Man, (a different string on website: Reasonable man instead a reasonable man)\n",
    "            #maybe I should remove all As, let's try\n",
    "            #\n",
    "            #song_no_quotes = (song_no_quotes.replace(\"A \",\"\")) was messing the Startr A War song title\n",
    "            #another exception is Slow Show[25], the naming is not consistent, so I need to hard code some titles\n",
    "            if song_no_quotes == \"Slow Show[25]\":\n",
    "                song_no_quotes = \"Slow Show\"\n",
    "            elif song_no_quotes == \"A Reasonable Man\":\n",
    "                song_no_quotes = \"Reasonable Man\"\n",
    "            elif song_no_quotes == \"I'Ll Still Destroy You\":\n",
    "                song_no_quotes = \"I'll Still Destroy You\"\n",
    "\n",
    "\n",
    "            print(song_no_quotes)\n",
    "\n",
    "            link = driver.find_element_by_partial_link_text(song_no_quotes).get_attribute('href')  \n",
    "\n",
    "            print(link)\n",
    "\n",
    "\n",
    "            page_response = requests.get(link, timeout=10)\n",
    "        # here, we fetch the content from the url, using the requests library\n",
    "            soup = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "\n",
    "            lenght = len(soup.findAll(\"div\", attrs={'class': None}))\n",
    "            print(lenght)\n",
    "            for i in range(0, lenght):\n",
    "                paragraphs = soup.findAll(\"div\", attrs={'class': None})[i].text\n",
    "                if len(paragraphs)>0: #chec there is anything in the string\n",
    "\n",
    "                    filename = ''.join(song_no_quotes.split()).lower()\n",
    "                    f= open(filename,\"w+\")#first we get an empty string\n",
    "\n",
    "                    f.write(paragraphs.strip())\n",
    "                    f.close() \n",
    "#         <a href=\"../lyrics/national/youvedoneitagainvirginia.html\" target=\"_blank\">You've Done It Again, Virginia</a>\n",
    "#         You've Done It Again, Virginia\n",
    "#         You've Done It Again, Virginia\n",
    "#         \"You've Done It Again, Virginia\"\n",
    "        break #remove break if you want to run everything at once\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will create folders with lyrics, saved as txt files. When running the script I got blocked by the https://www.azlyrics.com website. I tried using a private ip address but was still getting blocked, so I used ProtonVPN (free version), to be able to complete my song download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The above code does everything I need, below are my attempts before reaching the final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'str'>\n",
      "Stand up straight at the foot of your love\r\n",
      "I'll lift my shirt up\r\n",
      "Stand up straight at the foot of your love\r\n",
      "I'll lift my shirt up\n",
      "\r\n",
      "I was carried to Ohio in a swarm of bees\r\n",
      "I never married but Ohio don't remember me\n",
      "\r\n",
      "Lay my head on the hood of your car\r\n",
      "I take it too far\r\n",
      "Lay my head on the hood of your car\r\n",
      "I take it too far\n",
      "\r\n",
      "I still owe money to the money to the money I owe\r\n",
      "I never thought about love when I thought about home\r\n",
      "I still owe money to the money to the money I owe\r\n",
      "The floors are falling out from everybody I know\n",
      "\r\n",
      "I'm on a bloodbuzz\r\n",
      "Yes I am\r\n",
      "I'm on a blood...buzz\r\n",
      "I'm on a bloodbuzz\r\n",
      "God I am\r\n",
      "I'm on a blood...buzz\n",
      "\r\n",
      "I was carried to Ohio in a swarm of bees\r\n",
      "I never married but Ohio don't remember me\n",
      "\r\n",
      "I still owe money to the money to the money I owe\r\n",
      "I never thought about love when I thought about home\r\n",
      "I still owe money to the money to the money I owe\r\n",
      "The floors are falling out from everybody I know\n",
      "\r\n",
      "I'm on a bloodbuzz\r\n",
      "Yes I am\r\n",
      "I'm on a blood...buzz\r\n",
      "I'm on a bloodbuzz\r\n",
      "God I am\r\n",
      "I'm on a blood...buzz\n",
      "1048\n"
     ]
    }
   ],
   "source": [
    "#try scraping one song and print it\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page_link = \"https://www.azlyrics.com/lyrics/national/bloodbuzzohio.html\"\n",
    "#page_link = \"https://www.azlyrics.com/lyrics/national/sorrow.html\"\n",
    "# this is the url that we've already determined is safe and legal to scrape from.\n",
    "page_response = requests.get(page_link, timeout=5)\n",
    "# here, we fetch the content from the url, using the requests library\n",
    "page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "#we use the html parser to parse the url content and store it in a variable.\n",
    "textContent = []\n",
    "# for i in range(0, 20):\n",
    "#     paragraphs = page_content.findAll(\"div\", attrs={'class': None})[i].text\n",
    "#     print(paragraphs)\n",
    "#count paragraphs\n",
    "lenght = len(page_content.findAll(\"div\", attrs={'class': None}))\n",
    "print(lenght)\n",
    "for i in range(0, lenght):\n",
    "    paragraphs = page_content.findAll(\"div\", attrs={'class': None})[i].text\n",
    "   \n",
    "    if len(paragraphs)>0: #chec there is anything in the string\n",
    "        print(type(paragraphs))\n",
    "        #print(paragraphs)\n",
    "        print(paragraphs.strip())\n",
    "        print(len(paragraphs.lstrip()))\n",
    "        \n",
    "   \n",
    "        new = (paragraphs.splitlines())[2:] #show all extra lines\n",
    "        #print(paragraphs.split('\\n')[2:])\n",
    "       # paragraphs.splitlines()[1]\n",
    "        f= open(\"song2.txt\",\"w+\")#first we get an empty string\n",
    " \n",
    "        f.write(paragraphs.strip())\n",
    "     #   f.write(str(new))\n",
    "        f.close() \n",
    "    #this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\theVirginiaEP\n",
      "C:\\Users\\karol\\jupyter_startUp_dir\\TheNationalSongMaker\\theVirginiaEP\n"
     ]
    }
   ],
   "source": [
    "#getting the path right\n",
    "import os\n",
    "pathCore = \"C:\\\\Users\\\\karol\\\\jupyter_startUp_dir\\\\TheNationalSongMaker\"\n",
    "pathToAlbumFolder = pathCore + \"\\\\\" + \"theVirginiaEP\"\n",
    "print(pathToAlbumFolder)\n",
    "\n",
    "if not os.path.exists(pathToAlbumFolder):\n",
    "    os.makedirs(pathToAlbumFolder)\n",
    "os.chdir(pathToAlbumFolder)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Reasonable Man \n"
     ]
    }
   ],
   "source": [
    "text = \"A Reasonable Man (I Don'T Mind)\"\n",
    "text1= text.split('(')[0]\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Don't Mind The\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.capwords(\"I don't mind the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Don't Mind The Dolled-Up\n",
      "I Don't Mind The Dolled-Up\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def lowercase_match_group(matchobj):\n",
    "    return matchobj.group().lower()\n",
    "\n",
    "def title_extended(title):\n",
    "    if title is not None:\n",
    "        # Take advantage of title(), we'll fix the apostrophe issue afterwards\n",
    "        title = title.title()\n",
    "\n",
    "        # Special handling for contractions\n",
    "        poss_regex = r\"(?<=[a-z])[\\']([A-Z])\"\n",
    "        title = re.sub(poss_regex, lowercase_match_group, title)\n",
    "\n",
    "    return title\n",
    "\n",
    "def title_one_liner(title):\n",
    "    return re.sub(r\"(?<=[a-z])[\\']([A-Z])\", lambda x: x.group().lower(), title.title())\n",
    "\n",
    "str12 = \"I don't mind the dolled-up\"\n",
    "print(title_extended(str1))\n",
    "\n",
    "def title_one_liner(title):\n",
    "    return re.sub(r\"(?<=[a-z])[\\']([A-Z])\", lambda x: x.group().lower(), title.title())\n",
    "print(title_one_liner(str12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to use different user agents and ip addresses to get around website blocking scraping, eventually used a VPN\n",
    "\n",
    "#driver = webdriver.Chrome(\"C:/Users/karol/drivers/chromedriver\", options.add_argument('--proxy-server={170.81.37.34}'.format(proxy)))\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "print(userAgent)\n",
    "\n",
    "PROXY = \"200.255.122.174:8080\" # IP:PORT or HOST:PORT\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--proxy-server=%s' % PROXY)\n",
    "chrome_options.add_argument(f'user-agent={userAgent}')\n",
    "\n",
    "chrome = webdriver.Chrome(\"C:/Users/karol/drivers/chromedriver\",options=chrome_options)\n",
    "#chrome.get(\"https://www.azlyrics.com/lyrics/national/bloodbuzzohio.html\")\n",
    "chrome.get(\"https://www.azlyrics.com/\")\n",
    "\n",
    "                            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
