{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this code is to get a list of non-repeating songs by \"The National\" from Wikipedia, stripped from any additinal information, just song titles. We are only focusing on album songs (and EPs).\n",
    "\n",
    "First we need to build a SPARQL query to get the list of \"The National\" albums.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cherry Tree</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cherry_Tree_(EP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Virginia EP</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Virginia_EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boxer</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Boxer_(The_Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trouble Will Find Me</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Trouble_Will_Fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad Songs for Dirty Lovers</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sad_Songs_for_Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High Violet</td>\n",
       "      <td>https://en.wikipedia.org/wiki/High_Violet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alligator</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alligator_(The_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The National</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_National_(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sleep Well Beast</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sleep_Well_Beast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        album  \\\n",
       "0                 Cherry Tree   \n",
       "1             The Virginia EP   \n",
       "2                       Boxer   \n",
       "3        Trouble Will Find Me   \n",
       "4  Sad Songs for Dirty Lovers   \n",
       "5                 High Violet   \n",
       "6                   Alligator   \n",
       "7                The National   \n",
       "8            Sleep Well Beast   \n",
       "\n",
       "                                             article  \n",
       "0     https://en.wikipedia.org/wiki/Cherry_Tree_(EP)  \n",
       "1      https://en.wikipedia.org/wiki/The_Virginia_EP  \n",
       "2  https://en.wikipedia.org/wiki/Boxer_(The_Natio...  \n",
       "3  https://en.wikipedia.org/wiki/Trouble_Will_Fin...  \n",
       "4  https://en.wikipedia.org/wiki/Sad_Songs_for_Di...  \n",
       "5          https://en.wikipedia.org/wiki/High_Violet  \n",
       "6  https://en.wikipedia.org/wiki/Alligator_(The_N...  \n",
       "7  https://en.wikipedia.org/wiki/The_National_(al...  \n",
       "8     https://en.wikipedia.org/wiki/Sleep_Well_Beast  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GOAL: get a list of albums and songs\n",
    "\n",
    "\n",
    "#useful links\n",
    "#http://docs.python-requests.org/en/master/user/quickstart/\n",
    "#https://janakiev.com/blog/wikidata-mayors/\n",
    "\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "#test sparql query here: https://query.wikidata.org/\n",
    "url = 'https://query.wikidata.org/sparql'\n",
    "\n",
    "#the below is only getting us albums, to get more songs I would also like to\n",
    "#add EPs, extended plays\n",
    "\n",
    "# query = \"\"\"\n",
    "\n",
    "# SELECT ?album ?albumLabel ?article WHERE {\n",
    "#   SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    " \n",
    "#   ?album wdt:P31 wd:Q482994.  #?album wdt:P31 wd:Q482994. #is an Album\n",
    "#   ?album wdt:P175 wd:Q1142566.  # hasPerformerproperty \"The National\"\n",
    "    \n",
    "#   ?article schema:about ?album .\n",
    "#   ?article schema:inLanguage \"en\" .\n",
    "#   ?article schema:isPartOf <https://en.wikipedia.org/> .\n",
    "  \n",
    "# }\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "#query including EPs\n",
    "\n",
    "#the below is only getting us albums, to get more songs I would also like to\n",
    "#add EPs, extended plays\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT ?album ?albumLabel ?article WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "  { ?album wdt:P31 wd:Q482994. }\n",
    "  UNION\n",
    "  { ?album wdt:P31 wd:Q169930. }\n",
    "  ?album wdt:P175 wd:Q1142566.\n",
    "  ?article schema:about ?album.\n",
    "  ?article schema:inLanguage \"en\".\n",
    "  ?article schema:isPartOf <https://en.wikipedia.org/>.\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "data = r.json()\n",
    "\n",
    "\n",
    "#data = r.json()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "albums = []\n",
    "for item in data['results']['bindings']:\n",
    "    albums.append(OrderedDict({\n",
    "        'album': item['albumLabel']['value'],\n",
    "        'article': item['article']['value']}))\n",
    "\n",
    "df = pd.DataFrame(albums)\n",
    "#df.set_index('albumLabel', inplace=True)\n",
    "#a list of The National Albums in a df\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to use the wikipedia API to get html of the webpages we are interested in, we could also use BeautifulSoup for this puppose. Here I'm combining Wikipedi aAPI and BeautifulSoup.BeautifulSoup lets me expract the parts I'm interested in. Fist, let's get songs from one album:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nobody Else Will Be There\"\n",
      "None\n",
      "None\n",
      "None\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "#print(wikipedia.summary(\"Sad Songs for Dirty Lovers\"))\n",
    "#print(wikipedia.content(\"Sad Songs for Dirty Lovers\"))\n",
    "\n",
    "\n",
    "#print(wikipedia.WikipediaPage(title = 'Metropolis (1927 film)').summary)\n",
    "#this will take page_id, get it!!!!\n",
    "\n",
    "\n",
    "#example\n",
    "#pageContent = wikipedia.WikipediaPage('Sad Songs for Dirty Lovers').content\n",
    "#\n",
    "#get content of a section\n",
    "#section = wikipedia.WikipediaPage('Sleep Well Beast').section(\"Promotion\")\n",
    "#print(wikipedia.WikipediaPage('Euclid').sections)\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').images)\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').sections)\n",
    "\n",
    "\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').html())\n",
    "# wont work: , cannot get a section of html page print(wikipedia.WikipediaPage('Sleep Well Beast').section(\"Track listing\").html())\n",
    "content=wikipedia.WikipediaPage('Sleep Well Beast').html()\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "table = soup.find('table',{'class':'tracklist'}) #hopefully the same for all pages\n",
    "#print(table)\n",
    "songs = table.find_all('td',{'style':'vertical-align:top'})\n",
    "\n",
    "for s in songs:\n",
    "    print(s.string)\n",
    "#print(songs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string function is not getting me songs in places where there are additional html parameters but the text function below does the job. \".text gets all the child strings and return concatenated using the given separator\" from https://stackoverflow.com/questions/25327693/difference-between-string-and-text-beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nobody Else Will Be There\"\n",
      "\"Day I Die\" (composed by The National)\n",
      "\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
      "\"The System Only Dreams in Total Darkness\"\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "soup= make_soup(\"https://en.wikipedia.org/wiki/Sleep_Well_Beast\")\n",
    "songsInAlbum=\"\"\n",
    "# find all table ,get the first\n",
    "table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "#table\n",
    "#iter over it\n",
    "for record in table.findAll('tr'):\n",
    "    albumdata=\"\"\n",
    "    #for data in record.findAll('td'):\n",
    "    for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "        print(data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Wasp Nest\"\n",
      " \n",
      "\"All the Wine\"\n",
      " \n",
      "\"All Dolled-Up in Straps\"\n",
      " \n",
      "\"Cherry Tree\"\n",
      " \n",
      "\"About Today\"\n",
      " \n",
      "\"Murder Me Rachael\" (Live)\n",
      " \n",
      "\"A Reasonable Man (I Don't Mind)\"\n",
      "Padma Newsome\n",
      "\"You've Done It Again, Virginia\"\n",
      " \n",
      "\"Santa Clara\"\n",
      " \n",
      "\"Blank Slate\"\n",
      " \n",
      "\"Tall Saint\" (Demo)\n",
      " \n",
      "\"Without Permission\"\n",
      "Caroline Martin\n",
      "\"Forever After Days\" (Demo)\n",
      " \n",
      "\"Rest of Years\" (Demo)\n",
      " \n",
      "\"Slow Show\" (Demo)\n",
      " \n",
      "\"Lucky You\" (Daytrotter Session)\n",
      " \n",
      "\"Mansion on the Hill\" (Live)\n",
      "Bruce Springsteen\n",
      "\"Fake Empire\" (Live)\n",
      " \n",
      "\"About Today\" (Live)\n",
      " \n",
      "\"Fake Empire\"\n",
      "Matt Berninger\n",
      "\"Mistaken for Strangers\"\n",
      "Matt Berninger, Scott Devendorf\n",
      "\"Brainy\"\n",
      "Matt Berninger, Carin Besser, Scott Devendorf\n",
      "\"Squalor Victoria\"\n",
      "Matt Berninger, Bryce Dessner\n",
      "\"Green Gloves\"\n",
      "Matt Berninger\n",
      "\"Slow Show[25]\"\n",
      "Matt Berninger, Scott Devendorf\n",
      "\"Apartment Story\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Start a War\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Guest Room\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Racing Like a Pro\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Ada\"\n",
      "Matt Berninger, Carin Besser, Scott Devendorf\n",
      "\"Gospel\"\n",
      "Matt Berninger, Carin Besser, Bryan Devendorf\n",
      "\"I Should Live in Salt\"\n",
      "\"Demons\"\n",
      "\"Don't Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)\n",
      "\"Fireproof\"\n",
      "\"Sea of Love\"\n",
      "\"Heavenfaced\" (Berninger, B. Dessner)\n",
      "\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)\n",
      "\"Graceless\"\n",
      "\"Slipped\"\n",
      "\"I Need My Girl\"\n",
      "\"Humiliation\" (Berninger, A. Dessner, B. Dessner)\n",
      "\"Pink Rabbits\"\n",
      "\"Hard to Find\" (Berninger, B. Dessner)\n",
      "\"Cardinal Song\"\n",
      "\"Slipping Husband\"\n",
      "\"90-Mile Water Wall\"\n",
      "\"It Never Happened\"\n",
      "\"Murder Me Rachael\"\n",
      "\"Thirsty\"\n",
      "\"Available\"\n",
      "\"Sugar Wife\"\n",
      "\"Trophy Wife\"\n",
      "\"Fashion Coat\"\n",
      "\"Patterns of Fairytales\"\n",
      "\"Lucky You\"\n",
      "\"Terrible Love\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Sorrow\"\n",
      "Berninger, A. Dessner\n",
      "\"Anyone's Ghost\"\n",
      "Berninger, Bryce Dessner\n",
      "\"Little Faith\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"Afraid of Everyone\"\n",
      "Berninger, A. Dessner\n",
      "\"Bloodbuzz Ohio\"\n",
      "Berninger, A. Dessner, Padma Newsome\n",
      "\"Lemonworld\"\n",
      "Berninger, B. Dessner\n",
      "\"Runaway\"\n",
      "Berninger, A. Dessner\n",
      "\"Conversation 16\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"England\"\n",
      "Berninger, A. Dessner\n",
      "\"Vanderlyle Crybaby Geeks\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)\n",
      "\"Karen\" (Berninger, Bryce Dessner)\n",
      "\"Lit Up\"\n",
      "\"Looking for Astronauts\"\n",
      "\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)\n",
      "\"Baby, We'll Be Fine\"\n",
      "\"Friend of Mine\"\n",
      "\"Val Jester\" (Berninger, B. Dessner)\n",
      "\"All the Wine\" (The National)\n",
      "\"Abel\"\n",
      "\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)\n",
      "\"City Middle\" (Berninger, B. Dessner)\n",
      "\"Mr. November\"\n",
      "\"Beautiful Head\"\n",
      "\"Cold Girl Fever\"\n",
      "\"The Perfect Song\"\n",
      "\"American Mary\"\n",
      "\"Son\"\n",
      "\"Pay for Me\"\n",
      "\"Bitters & Absolut\"\n",
      "\"John's Star\"\n",
      "\"Watching You Well\"\n",
      "\"Theory of the Crows\"\n",
      "\"29 Years\"\n",
      "\"Anna Freud\"\n",
      "\"Nobody Else Will Be There\"\n",
      "\"Day I Die\" (composed by The National)\n",
      "\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
      "\"The System Only Dreams in Total Darkness\"\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "#songsInAlbum=\"\"\n",
    "# find all table ,get the first\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "#table\n",
    "#iter over it\n",
    "    for record in table.findAll('tr'):\n",
    "        #albumdata=\"\"\n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "            print(data.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above gets all the song titles from all the albums and EPs. Now we need to store them in some data structure, trying with a list first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], ['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']]\n"
     ]
    }
   ],
   "source": [
    "#now put the song titles in a list\n",
    "#list of albums and eps with sublists of songs\n",
    "#print(df)\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "#careful, the df gets modified, so we need to create a copy to avoid modyfying the original\n",
    "df_copy =df.copy()\n",
    "albumdata = []\n",
    "for index, row in df_copy.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    \n",
    "    row['album'] = []\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "            #print(data.text)\n",
    "            row['album'].append(data.text)\n",
    "\n",
    "    albumdata.append(row['album'])\n",
    "\n",
    "print(albumdata)\n",
    "#I could do it this way but I'm losing album names which is not ideal.\n",
    "#a dictionary is probably better suited for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to store albums and songs is probably to have a dictionary where the keys are album names and values are songs of a given album."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cherry Tree': ['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], 'The Virginia EP': ['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], 'Boxer': ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], 'Trouble Will Find Me': ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], 'Sad Songs for Dirty Lovers': ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], 'High Violet': ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], 'Alligator': ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], 'The National': ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], 'Sleep Well Beast': ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "#album_dict = {} #both ways to initialise a dictionary are OK\n",
    "album_dict = dict()\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    article =row['article']\n",
    "    album =row['album']\n",
    "\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "    #songsInAlbum=\"\"\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "\n",
    "            album_dict.setdefault(album, []).append(data.text)\n",
    "\n",
    "#recipe here; http://code.activestate.com/recipes/52219-associating-multiple-values-with-each-key-in-a-dic/\n",
    "#https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary\n",
    "\n",
    "    \n",
    "print(album_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cherry Tree': ['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], 'The Virginia EP': ['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], 'Boxer': ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], 'Trouble Will Find Me': ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], 'Sad Songs for Dirty Lovers': ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], 'High Violet': ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], 'Alligator': ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], 'The National': ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], 'Sleep Well Beast': ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']}\n"
     ]
    }
   ],
   "source": [
    "#another way to do this\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "#album_dict = {} #both ways to initialise a dictionary are OK\n",
    "album_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    article =row['article']\n",
    "    album =row['album']\n",
    "\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "    #songsInAlbum=\"\"\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "\n",
    "            if album in album_dict:\n",
    "        # append the new song  to the existing album \n",
    "                album_dict[album].append(data.text)\n",
    "            else:\n",
    "        # create a new album \n",
    "                album_dict[album] = [data.text]\n",
    "\n",
    "#recipe here; https://stackoverflow.com/questions/3199171/append-multiple-values-for-one-key-in-a-dictionary\n",
    "#https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary\n",
    "\n",
    "    \n",
    "print(album_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the songs and save as a new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cherry Tree': ['Wasp Nest', 'All the Wine', 'All Dolled-Up in Straps', 'Cherry Tree', 'About Today', 'Murder Me Rachael', \"A Reasonable Man (I Don't Mind)\"], 'The Virginia EP': [\"You've Done It Again, Virginia\", 'Santa Clara', 'Blank Slate', 'Tall Saint', 'Without Permission', 'Forever After Days', 'Rest of Years', 'Slow Show', 'Lucky You', 'Mansion on the Hill', 'Fake Empire', 'About Today'], 'Boxer': ['Fake Empire', 'Mistaken for Strangers', 'Brainy', 'Squalor Victoria', 'Green Gloves', 'Slow Show', 'Apartment Story', 'Start a War', 'Guest Room', 'Racing Like a Pro', 'Ada', 'Gospel'], 'Trouble Will Find Me': ['I Should Live in Salt', 'Demons', \"Don't Swallow the Cap\", 'Fireproof', 'Sea of Love', 'Heavenfaced', 'This Is the Last Time', 'Graceless', 'Slipped', 'I Need My Girl', 'Humiliation', 'Pink Rabbits', 'Hard to Find'], 'Sad Songs for Dirty Lovers': ['Cardinal Song', 'Slipping Husband', '90-Mile Water Wall', 'It Never Happened', 'Murder Me Rachael', 'Thirsty', 'Available', 'Sugar Wife', 'Trophy Wife', 'Fashion Coat', 'Patterns of Fairytales', 'Lucky You'], 'High Violet': ['Terrible Love', 'Sorrow', \"Anyone's Ghost\", 'Little Faith', 'Afraid of Everyone', 'Bloodbuzz Ohio', 'Lemonworld', 'Runaway', 'Conversation 16', 'England', 'Vanderlyle Crybaby Geeks'], 'Alligator': ['Secret Meeting', 'Karen', 'Lit Up', 'Looking for Astronauts', 'Daughters of the SoHo Riots', \"Baby, We'll Be Fine\", 'Friend of Mine', 'Val Jester', 'All the Wine', 'Abel', 'The Geese of Beverly Road', 'City Middle', 'Mr. November'], 'The National': ['Beautiful Head', 'Cold Girl Fever', 'The Perfect Song', 'American Mary', 'Son', 'Pay for Me', 'Bitters & Absolut', \"John's Star\", 'Watching You Well', 'Theory of the Crows', '29 Years', 'Anna Freud'], 'Sleep Well Beast': ['Nobody Else Will Be There', 'Day I Die', 'Walk It Back', 'Faith, Certainty and the Presidency of George W. Bush', 'The System Only Dreams in Total Darkness', 'Born to Beg', 'Turtleneck', 'Empire Line', \"I'll Still Destroy You\", 'Guilty Party', 'Carin at the Liquor Store', 'Dark Side of the Gym', 'Sleep Well Beast']}\n"
     ]
    }
   ],
   "source": [
    "#get only song names\n",
    "#songs are only in double quotes, extract everything in double quotes  \n",
    "import re\n",
    "#re.findall(r'\"([^\"]*)\"', inputString)\n",
    "\n",
    "\n",
    "#also need to remove 25 from \"Slow Show[25]\"\n",
    "album_dict_cleaned = {}\n",
    "for key in album_dict:\n",
    "    #print(album_dict[key])\n",
    "    #only things in double quotes, get rid of double backslashes\n",
    "    pattern = r'\\[.*?\\]' #this pattern finds everything apart from things in square brackets, to deal with Slow Show {25}\n",
    "   # value_list =album_dict[key] #this is a list\n",
    "    value_list = re.findall(r'\"([^\"]*)\"', str(album_dict[key]).replace(\"\\\\\", \"\"))\n",
    "    #the above finds avarything in double qutes and replaces any slashes with nothing\n",
    "    for element in value_list:       \n",
    "        element_f = re.sub(pattern, '', element)\n",
    "        \n",
    "        if key in album_dict_cleaned:\n",
    "        # append the new song  to the existing album \n",
    "            album_dict_cleaned[key].append(element_f)\n",
    "        else:\n",
    "        # create a new album \n",
    "            album_dict_cleaned[key] = [element_f]\n",
    "    \n",
    "    \n",
    "print(album_dict_cleaned)    \n",
    "   #OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (I Don't Mind)\n"
     ]
    }
   ],
   "source": [
    "string = \"A Reasonable Man (I Don't Mind)\"\n",
    "pattern = r'\\[.*?\\]'\n",
    "#re.findall((r'\"([^\"]*)\"', re.sub(pattern, '', string).replace(\"\\\\\", \"\")\n",
    "#new = re.findall(\"^.*?(?=\\s\\()\", string)\n",
    "print(re.sub(\"^.*?(?=\\s\\()\", \"\",string))\n",
    "#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
