{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a complete list of \"The National\" albums and songs\n",
    "\n",
    "The goal of this code is to get a list of non-repeating songs by \"The National\" from Wikipedia, stripped from any additinal information, just song titles. We are only focusing on album songs (and EPs).\n",
    "\n",
    "First we need to build a SPARQL query to get the list of \"The National\" albums.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Virginia EP</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Virginia_EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cherry Tree</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cherry_Tree_(EP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sad Songs for Dirty Lovers</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sad_Songs_for_Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alligator</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alligator_(The_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boxer</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Boxer_(The_Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High Violet</td>\n",
       "      <td>https://en.wikipedia.org/wiki/High_Violet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The National</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_National_(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trouble Will Find Me</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Trouble_Will_Fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sleep Well Beast</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sleep_Well_Beast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        album  \\\n",
       "0             The Virginia EP   \n",
       "1                 Cherry Tree   \n",
       "2  Sad Songs for Dirty Lovers   \n",
       "3                   Alligator   \n",
       "4                       Boxer   \n",
       "5                 High Violet   \n",
       "6                The National   \n",
       "7        Trouble Will Find Me   \n",
       "8            Sleep Well Beast   \n",
       "\n",
       "                                             article  \n",
       "0      https://en.wikipedia.org/wiki/The_Virginia_EP  \n",
       "1     https://en.wikipedia.org/wiki/Cherry_Tree_(EP)  \n",
       "2  https://en.wikipedia.org/wiki/Sad_Songs_for_Di...  \n",
       "3  https://en.wikipedia.org/wiki/Alligator_(The_N...  \n",
       "4  https://en.wikipedia.org/wiki/Boxer_(The_Natio...  \n",
       "5          https://en.wikipedia.org/wiki/High_Violet  \n",
       "6  https://en.wikipedia.org/wiki/The_National_(al...  \n",
       "7  https://en.wikipedia.org/wiki/Trouble_Will_Fin...  \n",
       "8     https://en.wikipedia.org/wiki/Sleep_Well_Beast  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GOAL: get a list of albums and songs\n",
    "\n",
    "\n",
    "#useful links\n",
    "#http://docs.python-requests.org/en/master/user/quickstart/\n",
    "#https://janakiev.com/blog/wikidata-mayors/\n",
    "\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "#test sparql query here: https://query.wikidata.org/\n",
    "url = 'https://query.wikidata.org/sparql'\n",
    "\n",
    "#the below is only getting us albums, to get more songs I would also like to\n",
    "#add EPs, extended plays\n",
    "\n",
    "# query = \"\"\"\n",
    "\n",
    "# SELECT ?album ?albumLabel ?article WHERE {\n",
    "#   SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    " \n",
    "#   ?album wdt:P31 wd:Q482994.  #?album wdt:P31 wd:Q482994. #is an Album\n",
    "#   ?album wdt:P175 wd:Q1142566.  # hasPerformerproperty \"The National\"\n",
    "    \n",
    "#   ?article schema:about ?album .\n",
    "#   ?article schema:inLanguage \"en\" .\n",
    "#   ?article schema:isPartOf <https://en.wikipedia.org/> .\n",
    "  \n",
    "# }\n",
    "\n",
    "# \"\"\"\n",
    "#############################################################\n",
    "#query including EPs (extended plays) below\n",
    " \n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT ?album ?albumLabel ?article WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "  { ?album wdt:P31 wd:Q482994. }\n",
    "  UNION\n",
    "  { ?album wdt:P31 wd:Q169930. }\n",
    "  ?album wdt:P175 wd:Q1142566.\n",
    "  ?article schema:about ?album.\n",
    "  ?article schema:inLanguage \"en\".\n",
    "  ?article schema:isPartOf <https://en.wikipedia.org/>.\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "data = r.json()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "albums = []\n",
    "for item in data['results']['bindings']:\n",
    "    albums.append(OrderedDict({\n",
    "        'album': item['albumLabel']['value'],\n",
    "        'article': item['article']['value']}))\n",
    "\n",
    "df = pd.DataFrame(albums)\n",
    "#df.set_index('albumLabel', inplace=True)\n",
    "#a list of The National Albums in a df\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to use the wikipedia API to get html of the webpages we are interested in, we could also use BeautifulSoup for this puppose. Here I'm combining Wikipedi aAPI and BeautifulSoup. BeautifulSoup lets me expract the parts I'm interested in. First, let's get songs from one album:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nobody Else Will Be There\"\n",
      "None\n",
      "None\n",
      "None\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "from bs4 import BeautifulSoup\n",
    "#print(wikipedia.summary(\"Sad Songs for Dirty Lovers\"))\n",
    "#print(wikipedia.content(\"Sad Songs for Dirty Lovers\"))\n",
    "\n",
    "\n",
    "#print(wikipedia.WikipediaPage(title = 'Metropolis (1927 film)').summary)\n",
    "#this will take page_id, get it!!!!\n",
    "\n",
    "\n",
    "#example\n",
    "#pageContent = wikipedia.WikipediaPage('Sad Songs for Dirty Lovers').content\n",
    "#\n",
    "#get content of a section\n",
    "#section = wikipedia.WikipediaPage('Sleep Well Beast').section(\"Promotion\")\n",
    "#print(wikipedia.WikipediaPage('Euclid').sections)\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').images)\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').sections)\n",
    "\n",
    "\n",
    "#print(wikipedia.WikipediaPage('Sleep Well Beast').html())\n",
    "# wont work: , cannot get a section of html page print(wikipedia.WikipediaPage('Sleep Well Beast').section(\"Track listing\").html())\n",
    "content=wikipedia.WikipediaPage('Sleep Well Beast').html()\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "table = soup.find('table',{'class':'tracklist'}) #hopefully the same for all pages\n",
    "#print(table)\n",
    "songs = table.find_all('td',{'style':'vertical-align:top'})\n",
    "\n",
    "for s in songs:\n",
    "    print(s.string)\n",
    "#print(songs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string function is not getting me songs in places where there are additional html parameters but the text function below does the job. \".text gets all the child strings and return concatenated using the given separator\" from https://stackoverflow.com/questions/25327693/difference-between-string-and-text-beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nobody Else Will Be There\"\n",
      "\"Day I Die\" (composed by The National)\n",
      "\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
      "\"The System Only Dreams in Total Darkness\"\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "soup= make_soup(\"https://en.wikipedia.org/wiki/Sleep_Well_Beast\")\n",
    "songsInAlbum=\"\"\n",
    "# find all table ,get the first\n",
    "table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "#table\n",
    "#iter over it\n",
    "for record in table.findAll('tr'):\n",
    "    albumdata=\"\"\n",
    "    #for data in record.findAll('td'):\n",
    "    for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "        print(data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"You've Done It Again, Virginia\"\n",
      " \n",
      "\"Santa Clara\"\n",
      " \n",
      "\"Blank Slate\"\n",
      " \n",
      "\"Tall Saint\" (Demo)\n",
      " \n",
      "\"Without Permission\"\n",
      "Caroline Martin\n",
      "\"Forever After Days\" (Demo)\n",
      " \n",
      "\"Rest of Years\" (Demo)\n",
      " \n",
      "\"Slow Show\" (Demo)\n",
      " \n",
      "\"Lucky You\" (Daytrotter Session)\n",
      " \n",
      "\"Mansion on the Hill\" (Live)\n",
      "Bruce Springsteen\n",
      "\"Fake Empire\" (Live)\n",
      " \n",
      "\"About Today\" (Live)\n",
      " \n",
      "\"Wasp Nest\"\n",
      " \n",
      "\"All the Wine\"\n",
      " \n",
      "\"All Dolled-Up in Straps\"\n",
      " \n",
      "\"Cherry Tree\"\n",
      " \n",
      "\"About Today\"\n",
      " \n",
      "\"Murder Me Rachael\" (Live)\n",
      " \n",
      "\"A Reasonable Man (I Don't Mind)\"\n",
      "Padma Newsome\n",
      "\"Cardinal Song\"\n",
      "\"Slipping Husband\"\n",
      "\"90-Mile Water Wall\"\n",
      "\"It Never Happened\"\n",
      "\"Murder Me Rachael\"\n",
      "\"Thirsty\"\n",
      "\"Available\"\n",
      "\"Sugar Wife\"\n",
      "\"Trophy Wife\"\n",
      "\"Fashion Coat\"\n",
      "\"Patterns of Fairytales\"\n",
      "\"Lucky You\"\n",
      "\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)\n",
      "\"Karen\" (Berninger, Bryce Dessner)\n",
      "\"Lit Up\"\n",
      "\"Looking for Astronauts\"\n",
      "\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)\n",
      "\"Baby, We'll Be Fine\"\n",
      "\"Friend of Mine\"\n",
      "\"Val Jester\" (Berninger, B. Dessner)\n",
      "\"All the Wine\" (The National)\n",
      "\"Abel\"\n",
      "\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)\n",
      "\"City Middle\" (Berninger, B. Dessner)\n",
      "\"Mr. November\"\n",
      "\"Fake Empire\"\n",
      "Matt Berninger\n",
      "\"Mistaken for Strangers\"\n",
      "Matt Berninger, Scott Devendorf\n",
      "\"Brainy\"\n",
      "Matt Berninger, Carin Besser, Scott Devendorf\n",
      "\"Squalor Victoria\"\n",
      "Matt Berninger, Bryce Dessner\n",
      "\"Green Gloves\"\n",
      "Matt Berninger\n",
      "\"Slow Show[25]\"\n",
      "Matt Berninger, Scott Devendorf\n",
      "\"Apartment Story\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Start a War\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Guest Room\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Racing Like a Pro\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Ada\"\n",
      "Matt Berninger, Carin Besser, Scott Devendorf\n",
      "\"Gospel\"\n",
      "Matt Berninger, Carin Besser, Bryan Devendorf\n",
      "\"Terrible Love\"\n",
      "Matt Berninger, Aaron Dessner\n",
      "\"Sorrow\"\n",
      "Berninger, A. Dessner\n",
      "\"Anyone's Ghost\"\n",
      "Berninger, Bryce Dessner\n",
      "\"Little Faith\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"Afraid of Everyone\"\n",
      "Berninger, A. Dessner\n",
      "\"Bloodbuzz Ohio\"\n",
      "Berninger, A. Dessner, Padma Newsome\n",
      "\"Lemonworld\"\n",
      "Berninger, B. Dessner\n",
      "\"Runaway\"\n",
      "Berninger, A. Dessner\n",
      "\"Conversation 16\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"England\"\n",
      "Berninger, A. Dessner\n",
      "\"Vanderlyle Crybaby Geeks\"\n",
      "Berninger, Carin Besser, A. Dessner\n",
      "\"Beautiful Head\"\n",
      "\"Cold Girl Fever\"\n",
      "\"The Perfect Song\"\n",
      "\"American Mary\"\n",
      "\"Son\"\n",
      "\"Pay for Me\"\n",
      "\"Bitters & Absolut\"\n",
      "\"John's Star\"\n",
      "\"Watching You Well\"\n",
      "\"Theory of the Crows\"\n",
      "\"29 Years\"\n",
      "\"Anna Freud\"\n",
      "\"I Should Live in Salt\"\n",
      "\"Demons\"\n",
      "\"Don't Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)\n",
      "\"Fireproof\"\n",
      "\"Sea of Love\"\n",
      "\"Heavenfaced\" (Berninger, B. Dessner)\n",
      "\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)\n",
      "\"Graceless\"\n",
      "\"Slipped\"\n",
      "\"I Need My Girl\"\n",
      "\"Humiliation\" (Berninger, A. Dessner, B. Dessner)\n",
      "\"Pink Rabbits\"\n",
      "\"Hard to Find\" (Berninger, B. Dessner)\n",
      "\"Nobody Else Will Be There\"\n",
      "\"Day I Die\" (composed by The National)\n",
      "\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
      "\"The System Only Dreams in Total Darkness\"\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "#songsInAlbum=\"\"\n",
    "# find all table ,get the first\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "#table\n",
    "#iter over it\n",
    "    for record in table.findAll('tr'):\n",
    "        #albumdata=\"\"\n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "            print(data.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above gets all the song titles from all the albums and EPs. Now we need to store them in some data structure, trying with a list first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], ['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']]\n"
     ]
    }
   ],
   "source": [
    "#list of albums and eps with sublists of songs\n",
    "#print(df)\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "#careful, the df gets modified, so we need to create a copy to avoid modyfying the original\n",
    "df_copy =df.copy()\n",
    "albumdata = []\n",
    "for index, row in df_copy.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    \n",
    "    row['album'] = []\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "            #print(data.text)\n",
    "            row['album'].append(data.text)\n",
    "\n",
    "    albumdata.append(row['album'])\n",
    "\n",
    "print(albumdata)\n",
    "#I could do it this way but I'm losing album names which is not ideal.\n",
    "#a dictionary is probably better suited for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above looks fine but the best way to store albums and songs is probably to have a dictionary where the keys are album names and values are songs of a given album."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Virginia EP': ['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], 'Cherry Tree': ['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], 'Sad Songs for Dirty Lovers': ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], 'Alligator': ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], 'Boxer': ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], 'High Violet': ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], 'The National': ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], 'Trouble Will Find Me': ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], 'Sleep Well Beast': ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "#album_dict = {} #both ways to initialise a dictionary are OK\n",
    "album_dict = dict()\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    article =row['article']\n",
    "    album =row['album']\n",
    "\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "    #songsInAlbum=\"\"\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "\n",
    "            album_dict.setdefault(album, []).append(data.text)\n",
    "\n",
    "#recipe here; http://code.activestate.com/recipes/52219-associating-multiple-values-with-each-key-in-a-dic/\n",
    "#https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary\n",
    "\n",
    "    \n",
    "print(album_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Virginia EP': ['\"You\\'ve Done It Again, Virginia\"', '\\xa0', '\"Santa Clara\"', '\\xa0', '\"Blank Slate\"', '\\xa0', '\"Tall Saint\" (Demo)', '\\xa0', '\"Without Permission\"', 'Caroline Martin', '\"Forever After Days\" (Demo)', '\\xa0', '\"Rest of Years\" (Demo)', '\\xa0', '\"Slow Show\" (Demo)', '\\xa0', '\"Lucky You\" (Daytrotter Session)', '\\xa0', '\"Mansion on the Hill\" (Live)', 'Bruce Springsteen', '\"Fake Empire\" (Live)', '\\xa0', '\"About Today\" (Live)', '\\xa0'], 'Cherry Tree': ['\"Wasp Nest\"', '\\xa0', '\"All the Wine\"', '\\xa0', '\"All Dolled-Up in Straps\"', '\\xa0', '\"Cherry Tree\"', '\\xa0', '\"About Today\"', '\\xa0', '\"Murder Me Rachael\" (Live)', '\\xa0', '\"A Reasonable Man (I Don\\'t Mind)\"', 'Padma Newsome'], 'Sad Songs for Dirty Lovers': ['\"Cardinal Song\"', '\"Slipping Husband\"', '\"90-Mile Water Wall\"', '\"It Never Happened\"', '\"Murder Me Rachael\"', '\"Thirsty\"', '\"Available\"', '\"Sugar Wife\"', '\"Trophy Wife\"', '\"Fashion Coat\"', '\"Patterns of Fairytales\"', '\"Lucky You\"'], 'Alligator': ['\"Secret Meeting\" (Berninger, A. Dessner, Scott Devendorf)', '\"Karen\" (Berninger, Bryce Dessner)', '\"Lit Up\"', '\"Looking for Astronauts\"', '\"Daughters of the SoHo Riots\" (Berninger, B. Dessner, S. Devendorf)', '\"Baby, We\\'ll Be Fine\"', '\"Friend of Mine\"', '\"Val Jester\" (Berninger, B. Dessner)', '\"All the Wine\" (The National)', '\"Abel\"', '\"The Geese of Beverly Road\" (Berninger, A. Dessner, S. Devendorf)', '\"City Middle\" (Berninger, B. Dessner)', '\"Mr. November\"'], 'Boxer': ['\"Fake Empire\"', 'Matt Berninger', '\"Mistaken for Strangers\"', 'Matt Berninger, Scott Devendorf', '\"Brainy\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Squalor Victoria\"', 'Matt Berninger, Bryce Dessner', '\"Green Gloves\"', 'Matt Berninger', '\"Slow Show[25]\"', 'Matt Berninger, Scott Devendorf', '\"Apartment Story\"', 'Matt Berninger, Aaron Dessner', '\"Start a War\"', 'Matt Berninger, Aaron Dessner', '\"Guest Room\"', 'Matt Berninger, Aaron Dessner', '\"Racing Like a Pro\"', 'Matt Berninger, Aaron Dessner', '\"Ada\"', 'Matt Berninger, Carin Besser, Scott Devendorf', '\"Gospel\"', 'Matt Berninger, Carin Besser, Bryan Devendorf'], 'High Violet': ['\"Terrible Love\"', 'Matt Berninger, Aaron Dessner', '\"Sorrow\"', 'Berninger, A. Dessner', '\"Anyone\\'s Ghost\"', 'Berninger, Bryce Dessner', '\"Little Faith\"', 'Berninger, Carin Besser, A. Dessner', '\"Afraid of Everyone\"', 'Berninger, A. Dessner', '\"Bloodbuzz Ohio\"', 'Berninger, A. Dessner, Padma Newsome', '\"Lemonworld\"', 'Berninger, B. Dessner', '\"Runaway\"', 'Berninger, A. Dessner', '\"Conversation 16\"', 'Berninger, Carin Besser, A. Dessner', '\"England\"', 'Berninger, A. Dessner', '\"Vanderlyle Crybaby Geeks\"', 'Berninger, Carin Besser, A. Dessner'], 'The National': ['\"Beautiful Head\"', '\"Cold Girl Fever\"', '\"The Perfect Song\"', '\"American Mary\"', '\"Son\"', '\"Pay for Me\"', '\"Bitters & Absolut\"', '\"John\\'s Star\"', '\"Watching You Well\"', '\"Theory of the Crows\"', '\"29 Years\"', '\"Anna Freud\"'], 'Trouble Will Find Me': ['\"I Should Live in Salt\"', '\"Demons\"', '\"Don\\'t Swallow the Cap\" (Berninger, A. Dessner, Bryce Dessner)', '\"Fireproof\"', '\"Sea of Love\"', '\"Heavenfaced\" (Berninger, B. Dessner)', '\"This Is the Last Time\" (Berninger, A. Dessner, B. Dessner)', '\"Graceless\"', '\"Slipped\"', '\"I Need My Girl\"', '\"Humiliation\" (Berninger, A. Dessner, B. Dessner)', '\"Pink Rabbits\"', '\"Hard to Find\" (Berninger, B. Dessner)'], 'Sleep Well Beast': ['\"Nobody Else Will Be There\"', '\"Day I Die\" (composed by The National)', '\"Walk It Back\" (includes an excerpt from the article \"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])', '\"The System Only Dreams in Total Darkness\"', '\"Born to Beg\"', '\"Turtleneck\"', '\"Empire Line\"', '\"I\\'ll Still Destroy You\"', '\"Guilty Party\"', '\"Carin at the Liquor Store\"', '\"Dark Side of the Gym\"', '\"Sleep Well Beast\"']}\n"
     ]
    }
   ],
   "source": [
    "#another way to do this\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def make_soup(url):\n",
    "    thepage=urllib.request.urlopen(url)\n",
    "    soupdata=BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata\n",
    "\n",
    "\n",
    "#album_dict = {} #both ways to initialise a dictionary are OK\n",
    "album_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    soup= make_soup(row['article'])\n",
    "    article =row['article']\n",
    "    album =row['album']\n",
    "\n",
    "    table = soup.find_all('table', class_=\"tracklist\")[0]  # Only use the first table\n",
    "\n",
    "    for record in table.findAll('tr'):\n",
    "    #songsInAlbum=\"\"\n",
    "        \n",
    "        for data in record.findAll('td', style=\"vertical-align:top\"):\n",
    "\n",
    "            if album in album_dict:\n",
    "        # append the new song  to the existing album \n",
    "                album_dict[album].append(data.text)\n",
    "            else:\n",
    "        # create a new album \n",
    "                album_dict[album] = [data.text]\n",
    "\n",
    "#recipe here; https://stackoverflow.com/questions/3199171/append-multiple-values-for-one-key-in-a-dictionary\n",
    "#https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary\n",
    "\n",
    "    \n",
    "print(album_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to clean the songs (get only song names) and save them as a new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get only song names\n",
    "#songs are only in double quotes, extract everything in double quotes \n",
    "\n",
    "# this line is problematic: \"Walk It Back\" (includes an excerpt from the article \n",
    "#\"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
    "# the code that gets everything in double quotes needs to be fixed to take only first instance in double quotes\n",
    "import re\n",
    "#re.findall(r'\"([^\"]*)\"', inputString)\n",
    "\n",
    "\n",
    "#also need to remove 25 from \"Slow Show[25]\"\n",
    "album_dict_cleaned = {}\n",
    "for key in album_dict:\n",
    "    #print(album_dict[key])\n",
    "    #only things in double quotes, get rid of double backslashes\n",
    "    pattern = r'\\[.*?\\]' #this pattern finds everything apart from things in square brackets, to deal with Slow Show {25}\n",
    "   # value_list =album_dict[key] #this is a list\n",
    "    value_list = re.findall(r'\"([^\"]*)\"', str(album_dict[key]).replace(\"\\\\\", \"\"))\n",
    "    #the above finds avarything in double qutes and replaces any slashes with nothing\n",
    "    for element in value_list:       \n",
    "        element_f = re.sub(pattern, '', element)\n",
    "        \n",
    "        if key in album_dict_cleaned:\n",
    "        # append the new song  to the existing album \n",
    "            album_dict_cleaned[key].append(element_f)\n",
    "        else:\n",
    "        # create a new album \n",
    "            album_dict_cleaned[key] = [element_f]\n",
    "    \n",
    "    \n",
    "#print(album_dict_cleaned)    \n",
    "   #OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"You've Done It Again, Virginia\"\n",
      "did not find\n",
      "\"Santa Clara\"\n",
      "did not find\n",
      "\"Blank Slate\"\n",
      "did not find\n",
      "\"Tall Saint\"\n",
      "did not find\n",
      "\"Without Permission\"\n",
      "did not find\n",
      "\"Forever After Days\"\n",
      "did not find\n",
      "\"Rest of Years\"\n",
      "did not find\n",
      "\"Slow Show\"\n",
      "did not find\n",
      "\"Lucky You\"\n",
      "did not find\n",
      "\"Mansion on the Hill\"\n",
      "did not find\n",
      "\"Fake Empire\"\n",
      "did not find\n",
      "\"About Today\"\n",
      "did not find\n",
      "\"Wasp Nest\"\n",
      "did not find\n",
      "\"All the Wine\"\n",
      "did not find\n",
      "\"All Dolled-Up in Straps\"\n",
      "did not find\n",
      "\"Cherry Tree\"\n",
      "did not find\n",
      "\"About Today\"\n",
      "did not find\n",
      "\"Murder Me Rachael\"\n",
      "did not find\n",
      "\"A Reasonable Man (I Don't Mind)\"\n",
      "did not find\n",
      "\"Cardinal Song\"\n",
      "\"Slipping Husband\"\n",
      "\"90-Mile Water Wall\"\n",
      "\"It Never Happened\"\n",
      "\"Murder Me Rachael\"\n",
      "\"Thirsty\"\n",
      "\"Available\"\n",
      "\"Sugar Wife\"\n",
      "\"Trophy Wife\"\n",
      "\"Fashion Coat\"\n",
      "\"Patterns of Fairytales\"\n",
      "\"Lucky You\"\n",
      "\"Secret Meeting\"\n",
      "\"Karen\"\n",
      "\"Lit Up\"\n",
      "\"Looking for Astronauts\"\n",
      "\"Daughters of the SoHo Riots\"\n",
      "\"Baby, We'll Be Fine\"\n",
      "\"Friend of Mine\"\n",
      "\"Val Jester\"\n",
      "\"All the Wine\"\n",
      "\"Abel\"\n",
      "\"The Geese of Beverly Road\"\n",
      "\"City Middle\"\n",
      "\"Mr. November\"\n",
      "\"Fake Empire\"\n",
      "did not find\n",
      "\"Mistaken for Strangers\"\n",
      "did not find\n",
      "\"Brainy\"\n",
      "did not find\n",
      "\"Squalor Victoria\"\n",
      "did not find\n",
      "\"Green Gloves\"\n",
      "did not find\n",
      "\"Slow Show[25]\"\n",
      "did not find\n",
      "\"Apartment Story\"\n",
      "did not find\n",
      "\"Start a War\"\n",
      "did not find\n",
      "\"Guest Room\"\n",
      "did not find\n",
      "\"Racing Like a Pro\"\n",
      "did not find\n",
      "\"Ada\"\n",
      "did not find\n",
      "\"Gospel\"\n",
      "did not find\n",
      "\"Terrible Love\"\n",
      "did not find\n",
      "\"Sorrow\"\n",
      "did not find\n",
      "\"Anyone's Ghost\"\n",
      "did not find\n",
      "\"Little Faith\"\n",
      "did not find\n",
      "\"Afraid of Everyone\"\n",
      "did not find\n",
      "\"Bloodbuzz Ohio\"\n",
      "did not find\n",
      "\"Lemonworld\"\n",
      "did not find\n",
      "\"Runaway\"\n",
      "did not find\n",
      "\"Conversation 16\"\n",
      "did not find\n",
      "\"England\"\n",
      "did not find\n",
      "\"Vanderlyle Crybaby Geeks\"\n",
      "did not find\n",
      "\"Beautiful Head\"\n",
      "\"Cold Girl Fever\"\n",
      "\"The Perfect Song\"\n",
      "\"American Mary\"\n",
      "\"Son\"\n",
      "\"Pay for Me\"\n",
      "\"Bitters & Absolut\"\n",
      "\"John's Star\"\n",
      "\"Watching You Well\"\n",
      "\"Theory of the Crows\"\n",
      "\"29 Years\"\n",
      "\"Anna Freud\"\n",
      "\"I Should Live in Salt\"\n",
      "\"Demons\"\n",
      "\"Don't Swallow the Cap\"\n",
      "\"Fireproof\"\n",
      "\"Sea of Love\"\n",
      "\"Heavenfaced\"\n",
      "\"This Is the Last Time\"\n",
      "\"Graceless\"\n",
      "\"Slipped\"\n",
      "\"I Need My Girl\"\n",
      "\"Humiliation\"\n",
      "\"Pink Rabbits\"\n",
      "\"Hard to Find\"\n",
      "\"Nobody Else Will Be There\"\n",
      "\"Day I Die\"\n",
      "\"Walk It Back\"\n",
      "\"The System Only Dreams in Total Darkness\"\n",
      "\"Born to Beg\"\n",
      "\"Turtleneck\"\n",
      "\"Empire Line\"\n",
      "\"I'll Still Destroy You\"\n",
      "\"Guilty Party\"\n",
      "\"Carin at the Liquor Store\"\n",
      "\"Dark Side of the Gym\"\n",
      "\"Sleep Well Beast\"\n"
     ]
    }
   ],
   "source": [
    "#get only song names\n",
    "#better - final version below\n",
    "#songs are only in double quotes, extract everything in double quotes \n",
    "\n",
    "# this line is problematic: \"Walk It Back\" (includes an excerpt from the article \n",
    "#\"Faith, Certainty and the Presidency of George W. Bush\" by Ron Suskind, first published in The New York Times[43])\n",
    "# the code that gets everything in double quotes needs to be fixed to take only first instance in double quotes\n",
    "import re\n",
    "#re.findall(r'\"([^\"]*)\"', inputString)\n",
    "\n",
    "\n",
    "#also need to remove 25 from \"Slow Show[25]\"\n",
    "album_dict_cleaned = {}\n",
    "counter = 0\n",
    "for key in album_dict:\n",
    "    #print(album_dict[key])\n",
    "    #only things in double quotes, get rid of double backslashes\n",
    "    pattern = r'\\[.*?\\]' #this pattern finds everything apart from things in square brackets, to deal with Slow Show {25}\n",
    "   # value_list =album_dict[key] #this is a list\n",
    "   # value_list = str(album_dict[key]).replace(\"\\\\\", \"\")\n",
    "    value_list = album_dict[key]\n",
    "    #print(value_list)\n",
    "    #print(type(value_list))\n",
    "    #break\n",
    "    #the above finds avarything in double qutes and replaces any slashes with nothing\n",
    "    for element in value_list: \n",
    "        #re.findall(r'\"([^\"]*)\"', element)\n",
    "        match = re.search(r'\"([^\"]*)\"',element) \n",
    "        counter =counter+1\n",
    "        \n",
    "        if match:\n",
    "            #print((match.group())+str(counter))\n",
    "            \n",
    "            if key in album_dict_cleaned:\n",
    "        # append the new song  to the existing album \n",
    "                album_dict_cleaned[key].append(match.group())\n",
    "                print(match.group())\n",
    "            else:\n",
    "        # create a new album \n",
    "                album_dict_cleaned[key] = [match.group()]\n",
    "                print(match.group())\n",
    "        else:\n",
    "            print ('did not find')\n",
    "\n",
    "    \n",
    "#print(album_dict_cleaned)    \n",
    "   #OK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save everything in a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('theNationalSongDictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(album_dict_cleaned, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
